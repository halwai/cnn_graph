{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, '..')\n",
    "from lib import models, graph, coarsening, utils\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "import scipy.sparse\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Graphs.\n",
    "flags.DEFINE_integer('number_edges', 8, 'Graph: minimum number of edges per vertex.')\n",
    "flags.DEFINE_string('metric', 'euclidean', 'Graph: similarity measure (between features).')\n",
    "# TODO: change cgcnn for combinatorial Laplacians.\n",
    "flags.DEFINE_bool('normalized_laplacian', True, 'Graph Laplacian: normalized.')\n",
    "flags.DEFINE_integer('coarsening_levels', 4, 'Number of coarsened graphs.')\n",
    "\n",
    "# Directories.\n",
    "flags.DEFINE_string('dir_data', os.path.join('..', 'data', 'mnist'), 'Directory to store data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Feature graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4166 > 4096 edges\n",
      "Execution time: 0.30s\n",
      "[matrix([[ 0.        , -0.15267725, -0.0954518 , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [-0.15267725,  0.        , -0.14974779, ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [-0.0954518 , -0.1497478 ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        ..., \n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        , -0.14974946],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         -0.14974946,  0.        ]], dtype=float32), matrix([[ 0.        , -0.18835647,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [-0.18835647,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        ..., \n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        , -0.14583394],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         -0.14583394,  0.        ]], dtype=float32), matrix([[ 0.        , -0.2076326 , -0.09258062, ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [-0.2076326 ,  0.        , -0.37048575, ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [-0.09258062, -0.37048569,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        ..., \n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         -0.03462621,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ..., -0.03462621,\n",
      "          0.        , -0.088346  ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         -0.088346  ,  0.        ]], dtype=float32), matrix([[ 0.        , -0.37571234, -0.46541405, ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [-0.37571234,  0.        , -0.01709988, ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [-0.46541405, -0.01709988,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        ..., \n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        , -0.02070682],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         -0.02070682,  0.        ]], dtype=float32), matrix([[ 0.        , -0.4847652 ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [-0.48476523,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        ..., \n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ]], dtype=float32)] (1248, 1248)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+MAAAEyCAYAAACReQFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nupjCuIiIiIiIiEgX+38IK5EgtMDMtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8809b36208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def grid_graph(m, corners=False):\n",
    "    z = graph.grid(m)\n",
    "    dist, idx = graph.distance_sklearn_metrics(z, k=FLAGS.number_edges, metric=FLAGS.metric)\n",
    "    A = graph.adjacency(dist, idx)\n",
    "\n",
    "    # Connections are only vertical or horizontal on the grid.\n",
    "    # Corner vertices are connected to 2 neightbors only.\n",
    "    if corners:\n",
    "        import scipy.sparse\n",
    "        A = A.toarray()\n",
    "        A[A < A.max()/1.5] = 0\n",
    "        A = scipy.sparse.csr_matrix(A)\n",
    "        print('{} edges'.format(A.nnz))\n",
    "\n",
    "    print(\"{} > {} edges\".format(A.nnz//2, FLAGS.number_edges*m**2//2))\n",
    "    return A\n",
    "\n",
    "t_start = time.process_time()\n",
    "A = grid_graph(32, corners=False)\n",
    "A = graph.replace_random_edges(A, 0)\n",
    "graphs, perm = coarsening.coarsen(A, levels=FLAGS.coarsening_levels, self_connections=False)\n",
    "\n",
    "L = [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "print('Execution time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "graph.plot_spectrum(L)\n",
    "L = [A.toarray() for A in L]\n",
    "L = [graph.rescale_L(A) for A in L]\n",
    "print(L, L[0].shape)\n",
    "#del A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248\n",
      "(45000, 1024, 3) (10000, 1024, 3) (5000, 1024, 3)\n",
      "Execution time: 6.36s\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2],X_train.shape[3])\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2],X_test.shape[3])\n",
    "y_train = y_train.reshape(y_train.shape[0])\n",
    "y_test = y_test.reshape(y_test.shape[0])\n",
    "\n",
    "rand_perm = np.random.permutation(X_train.shape[0])\n",
    "r = 45000\n",
    "\n",
    "train_data = X_train[rand_perm[0:r],:,:]\n",
    "val_data = X_train[rand_perm[r:],:,:]\n",
    "test_data = X_test\n",
    "train_labels = np_utils.to_categorical(y_train[rand_perm[0:r]])\n",
    "val_labels = np_utils.to_categorical(y_train[rand_perm[r:]])\n",
    "test_labels = np_utils.to_categorical(y_test)\n",
    "\n",
    "#train_data = X_train[rand_perm[0:r],:,0]\n",
    "#val_data = X_train[rand_perm[r:],:,0]\n",
    "#test_data = X_test[:,:,0]\n",
    "\n",
    "print(len(perm))\n",
    "print(train_data.shape, test_data.shape, val_data.shape)\n",
    "t_start = time.process_time()\n",
    "train_data = coarsening.perm_data(train_data, perm)\n",
    "val_data = coarsening.perm_data(val_data, perm)\n",
    "test_data = coarsening.perm_data(test_data, perm)\n",
    "print('Execution time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "#del perm,X_train,X_test\n",
    "\n",
    "L = np.array(L)\n",
    "single_laplacian =  np.array([q for q in L])\n",
    "#print(single_laplacian)\n",
    "train_laplacians = []\n",
    "for j in range(L.shape[0]):\n",
    "    train_laplacians.append([single_laplacian[j] for i in range(45000)])                        \n",
    "val_laplacians = []\n",
    "for j in range(L.shape[0]):\n",
    "    val_laplacians.append([single_laplacian[j] for i in range(10000)])\n",
    "test_laplacians = []\n",
    "for j in range(L.shape[0]):\n",
    "    test_laplacians.append([single_laplacian[j] for i in range(5000)])\n",
    "\n",
    "#print(len(train_laplacians))\n",
    "#for i in range(len(train_laplacians)):\n",
    "#    print(len(train_laplacians[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "common = {}\n",
    "common['dir_name']       = 'cifar10/'\n",
    "common['num_epochs']     = 2\n",
    "common['batch_size']     = 100\n",
    "common['decay_steps']    = (train_data.shape[0] + val_data.shape[0]) / common['batch_size']\n",
    "common['eval_frequency'] = 30 * common['num_epochs']\n",
    "common['brelu']          = 'b1relu'\n",
    "common['pool']           = 'mpool1'\n",
    "C = train_labels.shape[1]  # number of classes\n",
    "model_perf = utils.model_perf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN architecture\n",
      "  input: M_0 = 1248\n",
      "  layer 1: logits (softmax)\n",
      "    representation: M_1 = 10\n",
      "    weights: M_0 * M_1 = 1248 * 10 = 12480\n",
      "    biases: M_1 = 10\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas SGEMM launch failed : a.shape=(100, 3744), b.shape=(3744, 10), m=100, n=10, k=3744\n\t [[Node: logits/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape, logits/weights/read)]]\n\t [[Node: training/control/_31 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_350_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'logits/MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/halwai/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-ae1078812d45>\", line 18, in <module>\n    model_perf.test(models.cgcnn(L, **params), name, params,\n  File \"../lib/models.py\", line 896, in __init__\n    self.build_graph(M_0, F_0, M[-1], L)\n  File \"../lib/models.py\", line 228, in build_graph\n    op_logits = self.inference(self.ph_data, self.ph_laplacians ,self.ph_dropout)\n  File \"../lib/models.py\", line 257, in inference\n    logits = self._inference(data, laplacians, dropout)\n  File \"../lib/models.py\", line 1079, in _inference\n    x = self.fc(x, self.M[-1], relu=False)\n  File \"../lib/models.py\", line 1051, in fc\n    x = tf.matmul(x, W) + b\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 1765, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(100, 3744), b.shape=(3744, 10), m=100, n=10, k=3744\n\t [[Node: logits/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape, logits/weights/read)]]\n\t [[Node: training/control/_31 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_350_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(100, 3744), b.shape=(3744, 10), m=100, n=10, k=3744\n\t [[Node: logits/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape, logits/weights/read)]]\n\t [[Node: training/control/_31 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_350_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ae1078812d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_laplacians'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_laplacians\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     model_perf.test(models.cgcnn(L, **params), name, params,\n\u001b[0;32m---> 19\u001b[0;31m                     train_data, train_labels, val_data, val_labels , test_data, test_labels)\n\u001b[0m",
      "\u001b[0;32m/home/halwai/coursework/honors/Code/gcn_mdeff/cnn_graph/lib/utils.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(s, model, name, params, train_data, train_labels, val_data, val_labels, test_data, test_labels)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_accuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_laplacians\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_laplacians\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_f1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_laplacians\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/halwai/coursework/honors/Code/gcn_mdeff/cnn_graph/lib/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, train_labels, val_data, val_labels)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_loss_average\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  learning_rate = {:.2e}, loss_average = {:.2e}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(100, 3744), b.shape=(3744, 10), m=100, n=10, k=3744\n\t [[Node: logits/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape, logits/weights/read)]]\n\t [[Node: training/control/_31 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_350_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'logits/MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/halwai/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/halwai/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/halwai/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-ae1078812d45>\", line 18, in <module>\n    model_perf.test(models.cgcnn(L, **params), name, params,\n  File \"../lib/models.py\", line 896, in __init__\n    self.build_graph(M_0, F_0, M[-1], L)\n  File \"../lib/models.py\", line 228, in build_graph\n    op_logits = self.inference(self.ph_data, self.ph_laplacians ,self.ph_dropout)\n  File \"../lib/models.py\", line 257, in inference\n    logits = self._inference(data, laplacians, dropout)\n  File \"../lib/models.py\", line 1079, in _inference\n    x = self.fc(x, self.M[-1], relu=False)\n  File \"../lib/models.py\", line 1051, in fc\n    x = tf.matmul(x, W) + b\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 1765, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(100, 3744), b.shape=(3744, 10), m=100, n=10, k=3744\n\t [[Node: logits/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape, logits/weights/read)]]\n\t [[Node: training/control/_31 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_350_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    name = 'softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    params['regularization'] = 5e-4\n",
    "    params['dropout']        = 1\n",
    "    params['learning_rate']  = 0.02\n",
    "    params['decay_rate']     = 0.95\n",
    "    params['momentum']       = 0.9\n",
    "    params['F']              = []\n",
    "    params['F_0']            = 3\n",
    "    params['K']              = []\n",
    "    params['p']              = []\n",
    "    params['M']              = [C]\n",
    "    params['train_laplacians'] = train_laplacians\n",
    "    params['test_laplacians'] = val_laplacians\n",
    "    params['val_laplacians'] = test_laplacians\n",
    "    model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels , test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Common hyper-parameters for networks with one convolutional layer.\n",
    "common['regularization'] = 0\n",
    "common['dropout']        = 1\n",
    "common['learning_rate']  = 0.02\n",
    "common['decay_rate']     = 0.95\n",
    "common['momentum']       = 0.9\n",
    "common['F']              = [10]\n",
    "common['F_0']             = 3\n",
    "common['K']              = [20]\n",
    "common['p']              = [1]\n",
    "common['M']              = [C]\n",
    "common['train_laplacians'] = train_laplacians\n",
    "common['test_laplacians'] = val_laplacians\n",
    "common['val_laplacians'] = test_laplacians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Common hyper-parameters for LeNet5-like networks.\n",
    "common['regularization'] = 5e-4\n",
    "common['dropout']        = 0.5\n",
    "common['learning_rate']  = 0.02  # 0.03 in the paper but sgconv_sgconv_fc_softmax has difficulty to converge\n",
    "common['decay_rate']     = 0.95\n",
    "common['momentum']       = 0.9\n",
    "common['F']              = [32, 64]\n",
    "common['F_0']            = 3\n",
    "common['K']              = [25, 25]\n",
    "common['p']              = [4, 4]\n",
    "common['M']              = [512, C]\n",
    "common['train_laplacians'] = train_laplacians\n",
    "common['test_laplacians'] = val_laplacians\n",
    "common['val_laplacians'] = test_laplacians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN architecture\n",
      "  input: M_0 = 1312\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 1312 * 32 / 4 = 10496\n",
      "    weights: F_0 * F_1 * K_1 = 3 * 32 * 25 = 2400\n",
      "    biases: F_1 = 32\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 328 * 64 / 4 = 5248\n",
      "    weights: F_1 * F_2 * K_2 = 32 * 64 * 25 = 51200\n",
      "    biases: F_2 = 64\n",
      "  layer 3: fc1\n",
      "    representation: M_3 = 512\n",
      "    weights: M_2 * M_3 = 5248 * 512 = 2686976\n",
      "    biases: M_3 = 512\n",
      "  layer 4: logits (softmax)\n",
      "    representation: M_4 = 10\n",
      "    weights: M_3 * M_4 = 512 * 10 = 5120\n",
      "    biases: M_4 = 10\n",
      "0 th conv layer 100 1312 1312\n",
      "1 th conv layer 100 328 328\n",
      "  learning_rate = 2.00e-02, loss_average = 2.40e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 1.38e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 2.71e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 2.80e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 2.67e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 2.53e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 2.40e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 2.29e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 2.18e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 2.09e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.99e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.89e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.80e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.72e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.64e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.58e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.52e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.47e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.42e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.38e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.34e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.30e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.28e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.25e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.22e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.20e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.18e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.17e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.15e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.14e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.13e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.12e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.11e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.10e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.09e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.09e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.08e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.08e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.07e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.08e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.09e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.11e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.12e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.12e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.15e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.17e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.16e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.15e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.15e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.14e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.13e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.12e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.12e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.11e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.11e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.11e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.10e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.10e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.09e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.09e+01\n",
      "step 60 / 900 (epoch 0.13 / 2):\n",
      "  learning_rate = 2.00e-02, loss_average = 1.09e+01\n",
      "  validation accuracy: 9.86 (493 / 5000), f1 (weighted): 0.00, loss: 1.04e+01\n",
      "  time: 232s (wall 336s)\n",
      "  learning_rate = 2.00e-02, loss_average = 1.08e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.08e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.07e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.07e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.07e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.06e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.06e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.06e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.06e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.05e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.05e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.05e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.05e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.05e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.04e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "step 120 / 900 (epoch 0.27 / 2):\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  validation accuracy: 9.72 (486 / 5000), f1 (weighted): 0.00, loss: 1.02e+01\n",
      "  time: 444s (wall 652s)\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.03e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "step 180 / 900 (epoch 0.40 / 2):\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  validation accuracy: 9.82 (491 / 5000), f1 (weighted): 0.00, loss: 1.02e+01\n",
      "  time: 655s (wall 968s)\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.02e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "step 240 / 900 (epoch 0.53 / 2):\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  validation accuracy: 9.72 (486 / 5000), f1 (weighted): 0.00, loss: 1.01e+01\n",
      "  time: 944s (wall 1359s)\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.01e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "step 300 / 900 (epoch 0.67 / 2):\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  validation accuracy: 10.40 (520 / 5000), f1 (weighted): 0.00, loss: 1.00e+01\n",
      "  time: 1287s (wall 1804s)\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 1.00e+01\n",
      "  learning_rate = 2.00e-02, loss_average = 9.99e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.99e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.99e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.99e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.98e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.98e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.98e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.98e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.98e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.97e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.96e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.96e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.96e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.96e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.96e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.95e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.94e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.94e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.94e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.94e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.93e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.93e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.93e+00\n",
      "step 360 / 900 (epoch 0.80 / 2):\n",
      "  learning_rate = 2.00e-02, loss_average = 9.93e+00\n",
      "  validation accuracy: 9.26 (463 / 5000), f1 (weighted): 0.00, loss: 9.91e+00\n",
      "  time: 1576s (wall 2194s)\n",
      "  learning_rate = 2.00e-02, loss_average = 9.93e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.92e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.92e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.92e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.92e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.92e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.92e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.91e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.91e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.91e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.91e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.91e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.91e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.91e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.91e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.91e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.89e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.89e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.90e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.89e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.89e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.89e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.89e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.89e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.89e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.89e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.88e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.88e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.88e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.88e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.88e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.88e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.87e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.86e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.86e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.86e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.86e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.86e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.86e+00\n",
      "step 420 / 900 (epoch 0.93 / 2):\n",
      "  learning_rate = 2.00e-02, loss_average = 9.86e+00\n",
      "  validation accuracy: 9.86 (493 / 5000), f1 (weighted): 0.00, loss: 9.84e+00\n",
      "  time: 1791s (wall 2514s)\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.85e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.84e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.84e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.84e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.84e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.84e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.83e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.83e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.83e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.83e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.82e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.82e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.82e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.82e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.82e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.82e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.81e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.81e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.81e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.81e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.81e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.80e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.80e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.80e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.80e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.80e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.80e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.80e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.80e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.79e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.79e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.79e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.79e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.79e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.79e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.79e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.79e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.78e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.78e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.78e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.78e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.78e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.78e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.78e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.78e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.78e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "step 480 / 900 (epoch 1.07 / 2):\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  validation accuracy: 9.94 (497 / 5000), f1 (weighted): 0.00, loss: 9.76e+00\n",
      "  time: 2033s (wall 2859s)\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.77e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.76e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.76e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.75e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.76e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.76e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.75e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.75e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.75e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.75e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.75e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.74e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.75e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.74e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.74e+00\n",
      "  learning_rate = 2.00e-02, loss_average = 9.74e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.74e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.74e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.74e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.74e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.74e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.73e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.72e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.72e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.72e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.72e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.72e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.71e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.71e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.71e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.71e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.71e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.71e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.71e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "step 540 / 900 (epoch 1.20 / 2):\n",
      "  learning_rate = 1.90e-02, loss_average = 9.70e+00\n",
      "  validation accuracy: 9.86 (493 / 5000), f1 (weighted): 0.00, loss: 9.68e+00\n",
      "  time: 2331s (wall 3256s)\n",
      "  learning_rate = 1.90e-02, loss_average = 9.69e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.69e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.69e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.69e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.69e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.69e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.69e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.68e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.68e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.68e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.68e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.68e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.68e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.67e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.67e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.67e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.67e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.67e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.67e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.66e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.66e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.66e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.66e+00\n",
      "  learning_rate = 1.90e-02, loss_average = 9.66e+00\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    name = 'cgconv_cgconv_fc_softmax'  # 'Chebyshev'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    params['filter'] = 'chebyshev5'\n",
    "    model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_perf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    grid_params = {}\n",
    "    data = (train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "    utils.grid_search(params, grid_params, *data, model=lambda x: models.cgcnn(L,**x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
